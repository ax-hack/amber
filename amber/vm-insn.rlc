;
; rowl - 1st generation
; Copyright (C) 2010 nineties
;
; $Id: vm-insn.rlc 2015-06-21 14:28:03 nineties $
;

(define gen_field_get (idx) `(
    (asm "movl (%esi), %eax")
    (asm "movl " @(* 4 idx) "(%eax), %eax")
    (asm "movl %eax, (%esi)")
    ))

(define gen_field_set (idx) `(
    (asm "movl (%esi), %eax")
    (asm "movl 4(%esi), %ecx")
    (asm "addl $8, %esi")
    (asm "movl %ecx, " @(* 4 idx) "(%eax)")
    ))

(define gen_comparison1 (cmovname) `(
    (vmpop %eax)
    (asm "cmpl %edx, %eax")
    (asm "movl $3, %eax")
    (vmsshort 1 %ecx)
    (asm @cmovname " %ecx, %eax")
    (vmsucc %eax)
    (vmfetch)
    ))

(define gen_comparison2 (cmovname) `(
    (asm "movl (%esi), %eax")
    (asm "movl 4(%esi), %ecx")
    (asm "addl $8, %esi")
    (asm "cmpl %eax, %ecx")
    (asm "movl $3, %eax")
    (vmsshort 1 %ecx)
    (asm @cmovname " %ecx, %eax")
    (vmsucc %eax)
    (vmfetch)
    ))

(define gen_comparison3 (jmpname) `(
    (asm "movl (%esi), %eax")
    (asm "movl 4(%esi), %ecx")
    (asm "addl $8, %esi")
    (asm "fldl (%eax)")
    (asm "fldl (%ecx)")
    (asm "fcompp")
    (asm "fstsw %ax")
    (asm "sahf")
    (asm @jmpname " 1f")
    (vmsucc 3)
    (vmfetch)
    (asm "1:")
    (vmsshort 1 %eax)
    (vmsucc %eax)
    (vmfetch)
    ))

(define gen_comparison4 (v) `(
    (vmpop %eax)
    (asm "cmpl $" @v ", %eax")
    (asm "movl $3, %eax")
    (vmsshort 1 %ecx)
    (asm "cmove %ecx, %eax")
    (vmsucc %eax)
    (vmfetch)
    ))

(define gen_check_pstruct (type) `(
    (vmpop %eax)
    (asm "cmpl $" @SPECIAL_MAX ", %eax")
    (asm "jbe 1f")
    (asm "testl $1, %eax")
    (asm "jnz 1f")
    (asm "movl -4(%eax), %eax")
    ; XXX: should not hardcode the layout of object header.
    (asm "andl $" @(- (<< 1 9) 1) ", %eax")
    (asm "cmpl $" @(| (<< type 4) TAG_PSTRUCT) ", %eax")
    (asm "je 2f")
    (asm "1:")
    (vmsshort 1 %ecx)
    (vmsucc %ecx)
    (vmfetch)
    (asm "2:")
    (vmsucc 3)
    (vmfetch)
    ))

(define operand_len (opd) (assoc opd `((byte . 1) (short . 2) (ushort . 2) (int . 4) (prim . 2) (addr . 2) (laddr . 4) (object . 4))))
(define insn_length (operands) (do
    (var len 1) ; 1 for instruction code
    (foreach o operands (+= len (operand_len o)))
    len
    ))

(var RESET_MARK      0x00000100)
(var RESET_MARK_MASK 0x000000ff)

(var vm_instructions `(
    (nop   () @true ())
    (drop  () @true ((asm "addl $4, %esi")))
    (drop2 () @true ((asm "addl $8, %esi")))
    (dup   () @true ((asm "movl (%esi), %eax") (vmpush %eax)))
    (swap  () @true (
        (asm "movl (%esi), %eax")
        (asm "movl 4(%esi), %ecx")
        (asm "movl %eax, 4(%esi)")
        (asm "movl %ecx, (%esi)")
        ))
    ; 'rot:1' 'number of elements:1' 'shift:1'
    (rot (byte byte) @true (
        (vmubyte 1 %edx)
        (vmubyte 2 %ecx)
        (asm "shll $2, %edx")
        (asm "movl %esi, %eax")
        (asm "addl %edx, %eax")

        (asm "1:")
        (asm "testl %ecx, %ecx")
        (asm "jz 2f")
        (asm "subl $4, %eax")
        (asm "pushl (%eax)")
        (asm "subl $1, %ecx")
        (asm "jmp 1b")

        (asm "2:")
        (asm "movl %esi, %ecx")
        (asm "addl %edx, %ecx")

        (asm "3:")
        (asm "subl $4, %eax")
        (asm "subl $4, %ecx")
        (asm "movl (%eax), %edx")
        (asm "movl %edx, (%ecx)")
        (asm "cmpl %esi, %eax")
        (asm "je 4f")
        (asm "jmp 3b")

        (asm "4:")
        (vmubyte 2 %ecx)
        (asm "movl %esi, %eax")
        (asm "5:")
        (asm "testl %ecx, %ecx")
        (asm "jz 6f")
        (asm "popl %edx")
        (asm "movl %edx, (%eax)")
        (asm "subl $1, %ecx")
        (asm "addl $4, %eax")
        (asm "jmp 5b")

        (asm "6:")
        (asm "xorl %edx, %edx")
        ))
    (imm_im1   () @true ((vmpush $-1)))
    (imm_i0    () @true ((vmpush %edx))) ; also used for 'nil'
    (imm_i1    () @true ((vmpush $1)))
    (imm_i2    () @true ((vmpush $2)))
    (imm_i3    () @true ((vmpush $3)))
    (imm_i4    () @true ((vmpush $4)))
    (imm_i5    () @true ((vmpush $5)))
    (imm_int16 (short) @true ((vmsshort 1 %eax) (vmpush %eax)))
    (imm_int32 (int) @true ((vmint 1 %eax) (vmpush %eax)))
    (iadd      () @true ((vmbin "addl")))
    (isub      () @true ((vmbin "subl")))
    (iadd1 () @true ((asm "addl $1, (%esi)")))
    (isub1 () @true ((asm "subl $1, (%esi)")))

    (ineg  () @true ((asm "negl (%esi)")))
    (imul  () @true ((vmpop %eax) (asm "imul (%esi), %eax") (asm "movl %eax, (%esi)")))

    ; signed
    (idiv  () @true (
        (asm "movl (%esi), %ecx")
        (asm "movl 4(%esi), %eax")
        (asm "cltd")
        (asm "idivl %ecx")
        (asm "testl %edx, %edx")
        (asm "jz 1f")
        (asm "movl (%esi), %ecx")
        (asm "xorl 4(%esi), %ecx")
        (asm "jns 1f")
        (asm "subl $1, %eax")
        (asm "1:")
        (asm "addl $4, %esi")
        (asm "movl %eax, (%esi)")
        (asm "xorl %edx, %edx") ; clear zero register
        ))
    (imod  () @true (
        (asm "movl (%esi), %ecx")
        (asm "movl 4(%esi), %eax")
        (asm "cltd")
        (asm "idivl %ecx")
        (asm "testl %edx, %edx")
        (asm "jz 1f")
        (asm "movl (%esi), %eax")
        (asm "xorl 4(%esi), %eax")
        (asm "jns 1f")
        (asm "addl %ecx, %edx")
        (asm "1:")
        (asm "addl $4, %esi")
        (asm "movl %edx, (%esi)")
        (asm "xorl %edx, %edx") ; clear zero register
        ))

    ; unsigned
    (udiv  () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "divl %ecx")
        (asm "movl %eax, (%esi)")
        (asm "xorl %edx, %edx") ; clear zero register
        ))
    (umod  () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "divl %ecx")
        (asm "movl %edx, (%esi)")
        (asm "xorl %edx, %edx") ; clear zero register
        ))

    ; long unsigned division (64-bit)/(32-bit)
    ; this instruction is required for division of big-integer
    ; 
    ; ludiv h l d = floor( (h*2^32 + l)/d )
    ; quotient must be less than 2^32
    (ludiv  () @true (
        (vmpop %ecx)
        (vmpop %eax)
        (asm "movl (%esi), %edx")
        (asm "divl %ecx")
        (asm "movl %eax, (%esi)")
        (asm "xorl %edx, %edx")
        ))

    (shl   () @true (
        (vmpop %ecx)
        (asm "shll %cl, (%esi)")
        ))
    (shr   () @true (
        (vmpop %ecx)
        (asm "shrl %cl, (%esi)")
        ))
    (sal   () @true (
        (vmpop %ecx)
        (asm "sall %cl, (%esi)")
        ))
    (sar   () @true (
        (vmpop %ecx)
        (asm "sarl %cl, (%esi)")
        ))
    (bsr   () @true (
        (asm "movl (%esi), %eax")
        (asm "bsr %eax, %eax")
        (asm "cmovz %edx, %eax")
        (asm "movl %eax, (%esi)")
        ))
    (not    () @true ((asm "notl (%esi)")))
    (and    () @true ((vmbin "andl")))
    (or     () @true ((vmbin "orl")))
    (xor    () @true ((vmbin "xorl")))

    (box    () @true (
        (asm "sall $1, (%esi)")
        (asm "addl $1, (%esi)")
        ))
    (unbox  () @true (
        (asm "sarl $1, (%esi)")
        ))

    ; bigint arithmetic
    ; 1st argument must be big-integer
    ; 2nd argument must be big-integer or fixed-integer
    ; no run-time check is performed
    (badd   () @true (
        (asm "pushl %ebx")

        (asm "movl (%esi), %eax") ; rhs
        (asm "movl 4(%esi), %ebx") ; lhs
        (asm "movl 12(%eax), %eax") ; sign of rhs
        (asm "cmpl 12(%ebx), %eax")
        (asm "jne bsub_main") ; if rhs and lhs has different signs, switch to bsub
        ; compute (stp) += (eax)
        (asm "badd_main:")
        (asm "movl (%esi), %eax")
        (asm "movl 4(%esi), %ebx")
        (asm "movl 4(%ebx), %ecx")  ; number of digits of lhs
        (asm "cmpl 4(%eax), %ecx")   
        (asm "cmovl 4(%eax), %ecx")
        (asm "addl $1, %ecx") ; ecx = max(lhs.ndigit, rhs.ndigit) + 1
        (asm "cmpl 8(%ebx), %ecx") ; compare capa of lhs and ecx
        (asm "jle 2f")
        ; reserve array of lhs
        (asm "pushl %eax")
        (vmsave)
        (asm "pushl %ecx")
        (asm "movl 4(%esi), %eax")
        (asm "pushl %eax")
        (asm "call prim_resize_bint")
        (asm "addl $8, %esp")
        (vmrestore)
        (asm "popl %eax")
        (asm "2:")

        (asm "movl 4(%eax), %ecx")  ; %ecx = number of digits of rhs
        (asm "movl (%eax), %eax")   ; %eax = digits of rhs
        (asm "movl (%ebx), %ebx")   ; %ebx = digits of lhs

        ; while ecx > 0 { *ebx++ += *eax++ with carry }
        (asm "4:")
        (asm "addl %edx, (%ebx)")
        (asm "movl (%eax), %edx")
        (asm "addl %edx, (%ebx)")
        (asm "movl $0, %edx")
        (asm "adcl %edx, %edx")
        (asm "subl $1, %ecx")
        (asm "addl $4, %eax")
        (asm "addl $4, %ebx")
        (asm "testl %ecx, %ecx")
        (asm "jnz 4b")
        (asm "5:")
        (asm "addl %edx, (%ebx)")
        (asm "movl $0, %edx")
        (asm "adcl %edx, %edx")
        (asm "addl $4, %ebx")
        (asm "testl %edx, %edx")
        (asm "jnz 5b")

        ; update number of digits
        (asm "movl 4(%esi), %ebx")
        (asm "movl 8(%ebx), %ecx")
        (asm "movl (%ebx), %ebx")
        (asm "leal -4(%ebx,%ecx,4), %ebx")
        (asm "6:")
        (asm "movl (%ebx), %eax")
        (asm "testl %eax, %eax")
        (asm "jnz 8f")
        (asm "subl $1, %ecx")
        (asm "testl %ecx, %ecx")
        (asm "jz 7f")
        (asm "subl $4, %ebx")
        (asm "jmp 6b")
        (asm "7:")
        (asm "addl $1, %ecx")
        (asm "8:")
        (asm "movl 4(%esi), %ebx")
        (asm "movl %ecx, 4(%ebx)")

        (asm "xorl %edx, %edx")
        (asm "addl $4, %esi")
        (asm "popl %ebx")
        ))
    (bsub  () @true (
        (asm "pushl %ebx")

        (asm "movl (%esi), %eax") ; rhs
        (asm "movl 4(%esi), %ebx") ; lhs
        (asm "movl 12(%eax), %eax") ; sign of rhs
        (asm "cmpl 12(%ebx), %eax")
        (asm "jne badd_main") ; if rhs and lhs has different signs, switch to badd

        (asm "bsub_main:")
        (asm "movl (%esi), %eax")
        (asm "movl 4(%esi), %ebx")
        (asm "movl 4(%ebx), %ecx")  ; number of digits of lhs
        (asm "cmpl 4(%eax), %ecx")   
        (asm "cmovl 4(%eax), %ecx") ; max(lhs.ndigit, rhs.ndigit)
        (asm "cmpl 8(%ebx), %ecx") ; compare capa of lhs and ecx
        (asm "jle 2f")
        ; reserve array of lhs
        (asm "pushl %eax")
        (vmsave)
        (asm "pushl %ecx")
        (asm "movl 4(%esi), %eax")
        (asm "pushl %eax")
        (asm "call prim_resize_bint")
        (asm "addl $8, %esp")
        (vmrestore)
        (asm "popl %eax")
        (asm "2:")

        ; === compute lhs -= rhs === 
        ; 1. compare lhs.abs and rhs.abs
        (asm "movl 4(%ebx), %ecx")  ; ebx = lhs, eax = rhs
        (asm "cmpl 4(%eax), %ecx")  ; rhs.ndigit <=> lhs.ndigit
        (asm "ja 3f")
        (asm "jb 4f")
        (asm "movl (%ebx), %ebx")
        (asm "movl (%eax), %eax")
        (asm "subl $1, %ecx")
        (asm "leal (%eax,%ecx,4), %eax")
        (asm "leal (%ebx,%ecx,4), %ebx")
        (asm "5:")

        (asm "movl (%ebx), %edx")
        (asm "cmpl (%eax), %edx")   ; rhs.digits[ecx] <=> lhs.digits[ecx] 
        (asm "ja 3f")
        (asm "jb 4f")
        (asm "subl $1, %ecx")
        (asm "testl %ecx, %ecx")
        (asm "jnz 5b")

        ; 2. do computation
        (asm "3:") ; lhs.abs >= rhs.abs
        (asm "movl (%esi), %eax")
        (asm "movl 4(%esi), %ebx")
        (asm "movl 4(%eax), %ecx") ; rhs.ndigit
        (asm "movl (%eax), %eax") ; rhs.digits
        (asm "movl (%ebx), %ebx") ; lhs.digits
        (asm "xorl %edx, %edx") ; clear edx
        (asm "subl $4, %esp")

        (asm "6:")
        (asm "subl %edx, (%ebx)")
        (asm "movl $0, (%esp)")
        (asm "adcl $0, (%esp)")
        (asm "movl (%eax), %edx")
        (asm "subl %edx, (%ebx)")
        (asm "movl $0, %edx")
        (asm "adcl (%esp), %edx")
        (asm "subl $1, %ecx")
        (asm "addl $4, %eax")
        (asm "addl $4, %ebx")
        (asm "testl %ecx, %ecx")
        (asm "jnz 6b")
        (asm "7:")
        (asm "testl %edx, %edx")
        (asm "jz 14f")
        (asm "subl %edx, (%ebx)")
        (asm "movl $0, %edx")
        (asm "adcl %edx, %edx")
        (asm "addl $4, %ebx")
        (asm "jmp 7b")

        (asm "4:") ; lhs.abs < rhs.abs
        (asm "subl $4, %esp")
        (asm "movl (%esi), %eax")
        (asm "movl 4(%esi), %ebx")
        (asm "xorl $1, 12(%ebx)") 
        (asm "movl 4(%eax), %ecx")
        (asm "movl %ecx, (%esp)") ; rhs.ndigit
        (asm "movl 4(%ebx), %ecx") ; lhs.ndigit
        (asm "movl (%eax), %eax") ; rhs.digits
        (asm "movl (%ebx), %ebx") ; lhs.digits
        (asm "xorl %edx, %edx") ; clear edx

        (asm "12:")
        (asm "addl %edx, (%ebx)")
        (asm "movl (%eax), %edx")
        (asm "subl (%ebx), %edx")
        (asm "movl %edx, (%ebx)")
        (asm "movl $0, %edx")
        (asm "adcl %edx, %edx")
        (asm "subl $1, %ecx")
        (asm "subl $1, (%esp)")
        (asm "addl $4, %eax")
        (asm "addl $4, %ebx")
        (asm "testl %ecx, %ecx")
        (asm "jnz 12b")

        (asm "13:")
        (asm "movl (%esp), %ecx")
        (asm "testl %ecx, %ecx")
        (asm "jz 14f")

        (asm "movl (%eax), %ecx")
        (asm "subl %edx, %ecx")
        (asm "movl %ecx, (%ebx)")
        (asm "movl $0, %edx")
        (asm "adcl %edx, %edx")
        (asm "subl $1, (%esp)")
        (asm "addl $4, %eax")
        (asm "addl $4, %ebx")
        (asm "jmp 13b")

        (asm "14:")
        (asm "addl $4, %esp")
        (asm "8:")
        ; update number of digits
        (asm "movl 4(%esi), %ebx")
        (asm "movl 8(%ebx), %ecx")
        (asm "movl (%ebx), %ebx")
        (asm "leal -4(%ebx,%ecx,4), %ebx")
        (asm "9:")
        (asm "movl (%ebx), %eax")
        (asm "testl %eax, %eax")
        (asm "jnz 11f")
        (asm "subl $1, %ecx")
        (asm "testl %ecx, %ecx")
        (asm "jz 10f")
        (asm "subl $4, %ebx")
        (asm "jmp 9b")
        (asm "10:")
        (asm "addl $1, %ecx")
        (asm "11:")
        (asm "movl 4(%esi), %ebx")
        (asm "movl %ecx, 4(%ebx)")

        (asm "xorl %edx, %edx")
        (asm "addl $4, %esi")
        (asm "popl %ebx")
        ))
    (bmul  () @true (
        (asm "pushl %ebx")

        (asm "movl (%esi), %eax") ; rhs
        (asm "movl 4(%esi), %ebx") ; lhs
        (asm "movl 12(%eax), %eax"); sign of rhs
        (asm "xorl %eax, 12(%ebx)")

        (asm "movl 4(%ebx), %ecx") ; lhs.ndigit
        (asm "movl (%esi), %eax")
        (asm "imul 4(%eax), %ecx")
        (asm "addl $1, %ecx") ; lhs.ndigit * rhs.ndigit + 1
        ; allocate array for result

        (vmsave)
        (asm "pushl %ecx")
        (asm "call prim_allocate_iarray")
        (asm "addl $4, %esp")
        (vmrestore)

        ; setup variables
        (asm "subl $8, %esp")
        (asm "pushl %eax")        ; working array
        (asm "pushl 4(%ebx)")     ; lhs.ndigit
        (asm "pushl (%ebx)")      ; lhs.digits
        (asm "movl (%esi), %ebx")
        (asm "pushl 4(%ebx)")     ; rhs.ndigit
        (asm "pushl (%ebx)")      ; rhs.digits
        (asm "pushl $0")          ; index for rhs.digits
        (asm "pushl $0")          ; index for lhs.digits

        ; variable table
        ;   (%esp) : (i) index for lhs.digits
        ;  4(%esp) : (j) index for rhs.digits
        ;  8(%esp) : (v) rhs.digits
        ; 12(%esp) : (m) rhs.ndigit
        ; 16(%esp) : (u) lhs.digits
        ; 20(%esp) : (n) lhs.ndigit
        ; 24(%esp) : (w) working array
        ; 28(%esp) : v[j]
        ; 32(%esp) : working area

        (asm "1:")
        (asm "movl 4(%esp), %eax")
        (asm "cmpl %eax, 12(%esp)")
        (asm "je 4f") ; exit if j == m

        (asm "movl 8(%esp), %ebx")
        (asm "leal (%ebx, %eax, 4), %ebx")
        (asm "movl (%ebx), %ebx") ; ebx = v[j]
        (asm "movl %ebx, 28(%esp)")

        (asm "movl $0, (%esp)") ; i = 0
        (asm "xorl %ecx, %ecx")  ; carry = 0

        (asm "2:")

        (asm "movl (%esp), %eax")
        (asm "cmpl %eax, 20(%esp)")
        (asm "je 3f") ; exit if i == n

        (asm "movl 16(%esp), %ebx")
        (asm "leal (%ebx, %eax, 4), %eax")
        (asm "movl (%eax), %eax") ; eax = u[i]
        (asm "mull 28(%esp)") ; %edx:%eax = u[i] * v[j]
        (asm "addl %ecx, %eax") ; add carry
        (asm "adcl $0, %edx")

        (asm "movl %eax, 32(%esp)")

        (asm "movl (%esp), %eax")
        (asm "addl 4(%esp), %eax") ; eax = i + j
        (asm "movl 24(%esp), %ebx")
        (asm "leal (%ebx,%eax,4), %ecx")
        (asm "movl (%ecx), %ecx") ; ecx = w[i+j]
        (asm "addl %ecx, 32(%esp)")
        (asm "adcl $0, %edx")
        (asm "movl %edx, %ecx")
        (asm "movl 32(%esp), %edx")
        (asm "leal (%ebx, %eax, 4), %eax")
        (asm "movl %edx, (%eax)")

        (asm "addl $1, (%esp)")
        (asm "jmp 2b")

        (asm "3:")
        (asm "movl 4(%esp), %eax")
        (asm "addl 20(%esp), %eax") ; eax = n + j
        (asm "movl 24(%esp), %ebx")
        (asm "leal (%ebx, %eax, 4), %eax")
        (asm "movl %ecx, (%eax)")

        (asm "addl $1, 4(%esp)")
        (asm "jmp 1b")
        (asm "4:")

        ; w is the result
        (asm "movl 4(%esi), %eax") ; lhs
        (asm "movl 24(%esp), %ebx")
        (asm "movl %ebx, (%eax)")

        ; update lhs.ndigit
        (asm "movl 12(%esp), %ecx")
        (asm "imul 20(%esp), %ecx")
        (asm "addl $1, %ecx")
        (asm "movl %ecx, 8(%eax)")

        (asm "movl (%eax), %eax")
        (asm "leal -4(%eax,%ecx,4), %ebx")
        (asm "9:")
        (asm "movl (%ebx), %eax")
        (asm "testl %eax, %eax")
        (asm "jnz 11f")
        (asm "subl $1, %ecx")
        (asm "testl %ecx, %ecx")
        (asm "jz 10f")
        (asm "subl $4, %ebx")
        (asm "jmp 9b")
        (asm "10:")
        (asm "addl $1, %ecx")
        (asm "11:")
        (asm "movl 4(%esi), %ebx")
        (asm "movl %ecx, 4(%ebx)")

        (asm "addl $36, %esp")

        (asm "addl $4, %esi")
        (asm "xorl %edx, %edx")
        (asm "popl %ebx")
        ))

    (bcmp () @true (
        (asm "pushl %ebx")

        (asm "movl (%esi), %eax")   ; rhs
        (asm "movl 4(%esi), %ebx")  ; lhs
        (asm "movl 12(%eax), %eax") ; rhs.sign
        (asm "subl 12(%ebx), %eax") ; rhs.sign - lhs.sign
        (asm "jz 1f")
        (asm "movl %eax, 4(%esi)")
        (asm "jmp 2f")
        (asm "1:") ; rhs.sign == lhs.sign
        (asm "movl (%esi), %eax")  ; rhs
        (asm "movl 4(%esi), %ebx") ; lhs
        (asm "movl 4(%eax), %ecx") ; rhs.ndigit
        (asm "cmpl 4(%ebx), %ecx") ; rhs.ndigit - lhs.ndigit
        (asm "ja 3f")
        (asm "jb 4f")

        ; lhs.ndigit == rhs.ndigit
        (asm "6:")
        (asm "testl %ecx, %ecx")
        (asm "jz 7f")
        (asm "subl $1, %ecx")
        (asm "movl (%esi), %eax")
        (asm "movl 4(%esi), %ebx")
        (asm "movl (%eax), %eax") ; rhs.digits
        (asm "movl (%ebx), %ebx") ; lhs.digits
        (asm "leal (%eax,%ecx,4), %eax")
        (asm "leal (%ebx,%ecx,4), %ebx")
        (asm "movl (%eax), %edx")
        (asm "cmpl (%ebx), %edx") ; rhs.digit[ecx] - lhs.digit[ecx]
        (asm "ja 3f")
        (asm "jb 4f")
        (asm "jmp 6b")
        (asm "7:")
        (asm "movl $0, 4(%esi)")
        (asm "jmp 2f")
        (asm "3:") ; |lhs| < |rhs|
        (asm "movl $-1, 4(%esi)")
        (asm "jmp 5f")
        (asm "4:") ; |rhs| < |lhs|
        (asm "movl $1, 4(%esi)")
        (asm "5:")
        (asm "movl (%esi), %eax")
        (asm "cmp $0, 12(%eax)")
        (asm "je 2f")
        (asm "negl 4(%esi)")
        (asm "2:")

        (asm "addl $4, %esi")
        (asm "xorl %edx, %edx")
        (asm "popl %ebx")
        ))
    (bshl () @true (
        (asm "pushl %ebx")
        (asm "movl (%esi), %ecx")  ; shift length
        (asm "shrl $5, %ecx")      ; ecx = ecx/32
        (asm "movl 4(%esi), %eax") ; x
        (asm "movl 4(%eax), %ebx") ; x.ndigit
        (asm "addl %ecx, %ebx")    ; x.ndigit + ecx
        (asm "addl $1, %ebx")
        (asm "cmpl 8(%eax), %ebx") ; (x.ndigit + ecx + 1) <=> x.capa
        (asm "jbe 1f")
        (vmsave)
        (asm "pushl %ecx")
        (asm "pushl %ebx")
        (asm "pushl %eax")
        (asm "call prim_resize_bint")
        (asm "addl $8, %esp")
        (asm "popl %ecx")
        (vmrestore)
        (asm "1:")

        (asm "testl %ecx, %ecx")
        (asm "jz 10f") 
        ; shift (%esi) / 32
        (asm "movl 4(%esi), %eax") ; x
        (asm "movl (%eax), %ebx")  ; x.digits
        (asm "movl 4(%eax), %edx") ; x.ndigit
        (asm "addl %edx, %ecx")
        (asm "subl $4, %esp") ; copy of edx
        (asm "movl %edx, (%esp)")
        (asm "2:")
        (asm "movl (%esp), %edx")
        (asm "testl %edx, %edx")
        (asm "jz 3f")
        (asm "subl $1, (%esp)")
        (asm "movl (%esp), %edx")
        (asm "subl $1, %ecx")
        (asm "leal (%ebx,%edx,4), %edx")
        (asm "leal (%ebx,%ecx,4), %eax")
        (asm "movl (%edx), %edx")
        (asm "movl %edx, (%eax)")
        (asm "jmp 2b")
        (asm "3:")
        (asm "testl %ecx, %ecx")
        (asm "jz 4f")
        (asm "subl $1, %ecx")
        (asm "leal (%ebx,%ecx,4), %eax")
        (asm "movl $0, (%eax)")
        (asm "jmp 3b")
        (asm "4:")
        (asm "addl $4, %esp")
        (asm "10:")

        ; shift (%esi) % 32
        (asm "subl $8, %esp")
        (asm "movl 4(%esi), %ebx")
        (asm "movl (%ebx), %eax")
        (asm "movl %eax, (%esp)")
        (asm "movl 4(%ebx), %eax")
        (asm "movl (%esi), %ecx")
        (asm "shrl $5, %ecx")
        (asm "addl %ecx, %eax")
        (asm "addl $1, %eax")
        (asm "movl %eax, 4(%esp)")  
        (asm "movl (%esi), %ecx")
        (asm "andl $0x1f, %ecx") ; ecx = (shift length) % 32

        ; (%esp) : x.digits
        ; 4(%esp): x.ndigit

        (asm "5:")
        (asm "movl 4(%esp), %ebx")
        (asm "cmpl $1, %ebx")
        (asm "je 6f")
        (asm "subl $1, 4(%esp)")
        (asm "movl 4(%esp), %ebx")
        (asm "movl (%esp), %edx")
        (asm "leal (%edx,%ebx,4), %eax")
        (asm "leal -4(%edx,%ebx,4), %edx")
        (asm "movl (%eax), %eax")
        (asm "movl (%edx), %edx")
        (asm "shldl %cl, %edx, %eax")
        (asm "movl (%esp), %edx")
        (asm "leal (%edx,%ebx,4), %edx")
        (asm "movl %eax, (%edx)")
        (asm "jmp 5b")
        (asm "6:")
        (asm "movl (%esp), %eax")
        (asm "movl (%eax), %edx")
        (asm "shll %cl, %edx")
        (asm "movl %edx, (%eax)")
        (asm "addl $8, %esp")

        (asm "movl 4(%esi), %ebx")
        (asm "movl 8(%ebx), %ecx")
        (asm "movl (%ebx), %ebx")
        (asm "leal -4(%ebx,%ecx,4), %ebx")
        (asm "7:")
        (asm "movl (%ebx), %eax")
        (asm "testl %eax, %eax")
        (asm "jnz 9f")
        (asm "subl $1, %ecx")
        (asm "testl %ecx, %ecx")
        (asm "jz 8f")
        (asm "subl $4, %ebx")
        (asm "jmp 7b")
        (asm "8:")
        (asm "addl $1, %ecx")
        (asm "9:")
        (asm "movl 4(%esi), %ebx")
        (asm "movl %ecx, 4(%ebx)")

        (asm "xorl %edx, %edx")
        (asm "addl $4, %esi")
        (asm "popl %ebx")
        ))
    (bshr () @true (
        (asm "pushl %ebx")

        ; shift (%esi) / 32
        (asm "movl (%esi), %ecx")  ; shift length
        (asm "shrl $5, %ecx")      ; ecx = ecx/32
        (asm "testl %ecx, %ecx")
        (asm "jz 1f")
        (asm "movl 4(%esi), %eax") ; x
        (asm "movl (%eax), %ebx")  ; x.digits
        (asm "movl 4(%eax), %edx") ; x.ndigit
        (asm "subl %ecx, %edx")    ; x.ndigit - ecx
        (asm "2:")
        (asm "cmpl $0, %edx")
        (asm "jle 3f")
        (asm "leal (%ebx,%ecx,4), %eax")
        (asm "movl (%eax), %eax")
        (asm "movl %eax, (%ebx)")
        (asm "addl $4, %ebx")
        (asm "subl $1, %edx")
        (asm "jmp 2b")
        (asm "3:")

        ; clear leading words
        (asm "movl 4(%esi), %eax")  ; x
        (asm "movl (%eax), %ebx")   ; x.digits
        (asm "movl 4(%eax), %edx")  ; x.ndigit
        (asm "4:")
        (asm "testl %ecx, %ecx")
        (asm "jz 1f")
        (asm "subl $1, %ecx")
        (asm "subl $1, %edx")
        (asm "leal (%ebx,%edx,4), %eax")
        (asm "movl $0, (%eax)")
        (asm "jmp 4b")
        (asm "1:")

        ; shift (%esi) % 32
        (asm "subl $8, %esp")
        (asm "movl 4(%esi), %eax")  ; x
        (asm "movl (%eax), %ebx")   ; x.digits
        (asm "movl 4(%eax), %edx")  ; x.ndigit
        (asm "movl (%esi), %ecx")
        (asm "shrl $5, %ecx")
        (asm "subl %ecx, %edx")
        (asm "subl $1, %edx")
        (asm "movl %edx, 4(%esp)")
        (asm "movl $0, (%esp)")
        (asm "movl (%esi), %ecx")
        (asm "andl $0x1f, %ecx")

        ; (%esp):  index
        ; 4(%esp): n-1
        (asm "5:")
        (asm "movl (%esp), %edx")
        (asm "cmpl 4(%esp), %edx")
        (asm "jge 6f")
        (asm "leal (%ebx,%edx,4), %eax")
        (asm "leal 4(%ebx,%edx,4), %edx")
        (asm "movl (%eax), %eax")
        (asm "movl (%edx), %edx")
        (asm "shrdl %cl, %edx, %eax")
        (asm "movl (%esp), %edx")
        (asm "leal (%ebx,%edx,4), %edx")
        (asm "movl %eax, (%edx)")
        (asm "addl $1, (%esp)")
        (asm "jmp 5b")
        (asm "6:")
        (asm "leal (%ebx,%edx,4), %edx")
        (asm "movl (%edx), %eax")
        (asm "shrl %cl, %eax")
        (asm "movl %eax, (%edx)")
        (asm "addl $8, %esp")

        ; update number of digits
        (asm "movl 4(%esi), %ebx")
        (asm "movl 8(%ebx), %ecx")
        (asm "movl (%ebx), %ebx")
        (asm "leal -4(%ebx,%ecx,4), %ebx")
        (asm "7:")
        (asm "movl (%ebx), %eax")
        (asm "testl %eax, %eax")
        (asm "jnz 9f")
        (asm "subl $1, %ecx")
        (asm "testl %ecx, %ecx")
        (asm "jz 8f")
        (asm "subl $4, %ebx")
        (asm "jmp 7b")
        (asm "8:")
        (asm "addl $1, %ecx")
        (asm "9:")
        (asm "movl 4(%esi), %ebx")
        (asm "movl %ecx, 4(%ebx)")

        (asm "xorl %edx, %edx")
        (asm "addl $4, %esi")
        (asm "popl %ebx")
        ))

    (fneg () @true (
        (asm "movl (%esi), %eax")
        (asm "fldl (%eax)")
        (asm "fchs")
        (asm "fstpl (%eax)")
        ))
    (fadd () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "fldl (%ecx)")
        (asm "fldl (%eax)")
        (asm "faddp %st, %st(1)")
        (asm "fstpl (%eax)")
        ))
    (fsub () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "fldl (%ecx)")
        (asm "fldl (%eax)")
        (asm "fsubp %st, %st(1)")
        (asm "fstpl (%eax)")
        ))
    (fmul () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "fldl (%ecx)")
        (asm "fldl (%eax)")
        (asm "fmulp %st, %st(1)")
        (asm "fstpl (%eax)")
        ))
    (fdiv () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "fldl (%ecx)")
        (asm "fldl (%eax)")
        (asm "fdivp %st, %st(1)")
        (asm "fstpl (%eax)")
        ))
    (fabs () @true (
        (asm "movl (%esi), %eax")
        (asm "fldl (%eax)")
        (asm "fabs")
        (asm "fstpl (%eax)")
        ))
    (fsqrt () @true (
        (asm "movl (%esi), %eax")
        (asm "fldl (%eax)")
        (asm "fsqrt")
        (asm "fstpl (%eax)")
        ))
    (fcos () @true (
        (asm "movl (%esi), %eax")
        (asm "fldl (%eax)")
        (asm "fcos")
        (asm "fstpl (%eax)")
        ))
    (fsin () @true (
        (asm "movl (%esi), %eax")
        (asm "fldl (%eax)")
        (asm "fsin")
        (asm "fstpl (%eax)")
        ))
    (ftan () @true (
        (asm "movl (%esi), %ecx")
        (asm "fldl (%ecx)")
        (asm "fxam")
        (asm "fstsw %ax")
        (asm "sahf")
        (asm "jc 2f")

        (asm "1:")
        (asm "fptan")
        (asm "fstp %st(0)")
        (asm "fstsw %ax")
        (asm "sahf")
        (asm "jnp 3f")
        (asm "fldpi")
        (asm "fxch")
        (asm "fprem1")
        (asm "jmp 1b")

        (asm "2:")
        (asm "fldl NaN")

        (asm "3:")
        (asm "fstpl (%ecx)")
        ))

    ; compute x^y
    (fpow () @true (
        (vmpop %ecx)                ; y
        (asm "movl (%esi), %eax")   ; x
        (asm "fldl (%ecx)")         ; y
        (asm "fldl (%eax)")         ; x | y
        (asm "fyl2x")               ; y*log2(x)
        (asm "fst %st(1)")          ; y*log2(x) | y*log2(x) 
        (asm "frndint")             ; [y*log2(x)] | y*log2(x)
        (asm "fxch")                ; y*log2(x) | [y*log2(x)]
        (asm "fsub %st(1), %st")    ; y*log2(x)-[y*log2(x)] | [y*log2(x)]
        (asm "f2xm1")               ; 2^(y*log2(x)-[y*log2(x)])-1 | [y*log2(x)]
        (asm "fld1")
        (asm "faddp %st, %st(1)")   ; 2^(y*log2(x)-[y*log2(x)]) | [y*log2(x)]
        (asm "fscale")              ; 2^(y*log2(x)) = x^y
        (asm "fstpl (%eax)")
        ))

    ; compute log x (y)
    (flog () @true (
        (vmpop %ecx)                ; y
        (asm "movl (%esi), %eax")   ; x
        (asm "fld1")                ; 1.0
        (asm "fldl (%ecx)")         ; y | 1.0
        (asm "fyl2x")               ; log2(y)
        (asm "fld1")                ; 1.0 | log2(y)
        (asm "fldl (%eax)")         ; x | 1.0 | log2(y)
        (asm "fyl2x")               ; log2(x) | log2(y)
        (asm "fdivp %st, %st(1)")   ; log2(y)/log2(x)
        (asm "fstpl (%eax)")
        ))

    ; integer to float
    (itof () @true (
        (vmsave)
        (call prim_allocate_float)
        (vmrestore)
        (asm "fildl (%esi)")
        (asm "fstpl (%eax)")
        (asm "movl %eax, (%esi)")
        ))

    ; allocate cons object
    ; arg0 = cdr object
    ; arg1 = car object
    (cons () @true (
        (vmsave)
        (call allocate_cons)
        (vmrestore)
        (vmpop %ecx)
        (asm "movl %ecx, (%eax)")
        (asm "movl (%esi), %ecx")
        (asm "movl %ecx, 4(%eax)")
        (asm "movl %eax, (%esi)")
        ))
    ; decompose cons object
    ; arg0 = cons object
    (decons () @true (
        (asm "movl (%esi), %eax")
        (asm "movl 4(%eax), %ecx")
        (asm "movl %ecx, (%esi)")
        (asm "movl (%eax), %eax")
        (vmpush %eax)
        ))
    (list_at () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "0:")
        (asm "testl %ecx, %ecx")
        (asm "jz 1f")
        (asm "movl 4(%eax), %eax")
        (asm "subl $1, %ecx")
        (asm "jmp 0b")
        (asm "1:")
        (asm "movl (%eax), %eax")
        (asm "movl %eax, (%esi)")
        ))
    (list_from () @true (
        (vmpop %ecx)
        (asm "movl (%esi), %eax")
        (asm "0:")
        (asm "testl %ecx, %ecx")
        (asm "jz 1f")
        (asm "movl 4(%eax), %eax")
        (asm "subl $1, %ecx")
        (asm "jmp 0b")
        (asm "1:")
        (asm "movl %eax, (%esi)")
        ))
    (list_len () @true (
        (asm "movl (%esi), %eax")
        (asm "xorl %ecx, %ecx")
        (asm "0:")
        (asm "testl %eax, %eax")
        (asm "jz 1f")
        (asm "movl 4(%eax), %eax")
        (asm "addl $1, %ecx")
        (asm "jmp 0b")
        (asm "1:")
        (asm "movl %ecx, (%esi)")
    ))
    ; allocate plain object
    ; arg0 = size (in bytes)
    ; NB: allocated memory will not be zero-cleared
    (plain (byte) @true (
        (asm "movl (%esi), %eax")
        (vmsave)
        (asm "pushl %eax")
        (vmubyte 1 %eax) ; type of plain
        (asm "pushl %eax")
        (call allocate_pstruct)
        (asm "addl $8, %esp")
        (vmrestore)
        (asm "movl %eax, (%esi)")
        ))
    ; allocate tuple object
    ; opd0 = # of elements (8bit)
    ; opd1 = # of boxed elements (8bit)
    ; NB:
    ;  - allocated memory will not be zero-cleared
    ;  - all boxed elements must be placed first
    (struct (byte byte) @true (
        (vmsave)
        (asm "pushl %esi")
        (vmubyte 2 %eax) ; # of boxed elements
        (asm "pushl %eax")
        (vmubyte 1 %eax) ; # of elements
        (asm "pushl %eax")
        (asm "sall $2, %eax")
        (asm "addl %eax, %esi")
        (call allocate_struct_with_values)
        (asm "addl $12, %esp")
        (vmrestore)
        (vmpush %eax)
        ))
    ; allocate variant object
    ; opd0 = tag (16bit)
    ; opd1 = # of elements (8bit)
    ; opd2 = # of boxed elements (8bit)
    ; NB:
    ;  - allocated memory will not be zero-cleared
    ;  - field0 is for the tag
    ;  - do not rewrite the tag
    ;  - all boxed elements must be placed first
    (variant (short byte byte) @true (
        (vmsave)
        (asm "pushl %esi")
        (vmubyte 4 %eax) ; # of boxed elements
        (asm "pushl %eax")
        (vmubyte 3 %eax) ; # of elements
        (asm "pushl %eax")
        (asm "sall $2, %eax")
        (asm "addl %eax, %esi")
        (vmushort 1 %eax) ; tag
        (asm "pushl %eax")
        (call allocate_variant_with_values)
        (asm "addl $16, %esp")
        (vmrestore)
        (vmpush %eax)
        ))
    (field_get0 () @true @(gen_field_get 0)) ; also used for 'car'
    (field_get1 () @true @(gen_field_get 1)) ; also used for 'cdr'
    (field_get2 () @true @(gen_field_get 2))
    (field_get3 () @true @(gen_field_get 3))
    (field_get4 () @true @(gen_field_get 4))
    (field_get5 () @true @(gen_field_get 5))
    (field_get  (byte) @true (
        (vmubyte 1 %eax)
        (asm "sall $2, %eax")
        (asm "movl (%esi), %ecx")
        (asm "addl %ecx, %eax")
        (asm "movl (%eax), %eax")
        (asm "movl %eax, (%esi)")
        ))
    ; field_set obj val
    (field_set0 () @true @(gen_field_set 0)) ; also used for 'setcar'
    (field_set1 () @true @(gen_field_set 1)) ; also used for 'setcdr'
    (field_set2 () @true @(gen_field_set 2))
    (field_set3 () @true @(gen_field_set 3))
    (field_set4 () @true @(gen_field_set 4))
    (field_set5 () @true @(gen_field_set 5))
    (field_set  (byte) @true (
        (vmubyte 1 %eax) ; index
        (asm "sall $2, %eax")
        (asm "movl (%esi), %ecx")
        (asm "addl %eax, %ecx")
        (asm "movl 4(%esi), %eax")
        (asm "movl %eax, (%ecx)")
        (asm "addl $8, %esi")
        ))
    ; tuple nelem
    (tuple () @true (
        (asm "movl (%esi), %eax") ; # of elements
        (vmsave)
        (asm "pushl %eax")
        (call prim_allocate_tuple)
        (asm "addl $4, %esp")
        (vmrestore)
        (asm "movl %eax, (%esi)")
        ))
    ; array nelem
    (array () @true (
        (asm "movl (%esi), %eax") ; # of elements
        (vmsave)
        (asm "pushl %eax")
        (call prim_allocate_array)
        (asm "addl $4, %esp")
        (vmrestore)
        (asm "movl %eax, (%esi)")
        ))
    ; array_get ary idx
    (array_get8 () @true (
        (vmpop %eax) ; index
        (asm "movl (%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movsbl (%ecx), %eax")
        (asm "movl %eax, (%esi)")
        ))
    (array_get16 () @true (
        (vmpop %eax) ; index
        (asm "sall $1, %eax")
        (asm "movl (%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movswl (%ecx), %eax")
        (asm "movl %eax, (%esi)")
        ))
    (array_get32 () @true (
        (vmpop %eax) ; index
        (asm "sall $2, %eax")
        (asm "movl (%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movl (%ecx), %eax")
        (asm "movl %eax, (%esi)")
        ))
    ; array_get ary idx
    (array_getu8 () @true (
        (vmpop %eax) ; index
        (asm "movl (%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movzbl (%ecx), %eax")
        (asm "movl %eax, (%esi)")
        ))
    (array_getu16 () @true (
        (vmpop %eax) ; index
        (asm "sall $1, %eax")
        (asm "movl (%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movzwl (%ecx), %eax")
        (asm "movl %eax, (%esi)")
        ))
    ; array_set ary idx val
    (array_set8 () @true (
        (asm "movl 4(%esi), %eax") ; index
        (asm "movl 8(%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movl (%esi), %eax") ; value
        (asm "movb %al, (%ecx)")
        (asm "addl $12, %esi")
        ))
    (array_set16 () @true (
        (asm "movl 4(%esi), %eax") ; index
        (asm "sall $1, %eax")
        (asm "movl 8(%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movl (%esi), %eax") ; value
        (asm "movw %ax, (%ecx)")
        (asm "addl $12, %esi")
        ))
    (array_set32 () @true (
        (asm "movl 4(%esi), %eax") ; index
        (asm "sall $2, %eax")
        (asm "movl 8(%esi), %ecx") ; array
        (asm "addl %eax, %ecx")
        (asm "movl (%esi), %eax") ; value
        (asm "movl %eax, (%ecx)")
        (asm "addl $12, %esi")
        ))
    ; allocate stack area for local variables
    (allocate (byte) @true (
        (vmubyte 1 %eax)
        (asm "sall $2, %eax")
        (asm "subl %eax, %esi")
        ))
    ; deallocate stack area for local variables
    (deallocate () @true (
        (asm "movl %edi, %esi")
        ))
    ; number of arguments
    (arity () @true (
        (asm "movzbl 8(%edi), %eax") ; %eax = 4 * arity
        (asm "andl $" @RESET_MARK_MASK ", %eax")
        (asm "shrl $2, %eax")
        (vmpush %eax)
        ))
    ; arguments
    (args (byte) @true (
        (asm "subl $12, %esp")
        (asm "movzbl 8(%edi), %ecx") ; %ecx = 4 * arity
        (asm "leal 20(%edi,%ecx,1), %eax")
        (asm "movl %eax, (%esp)")
        (asm "shrl $2, %ecx")
        (vmubyte 1 %eax) ; offset
        (asm "subl %eax, %ecx")
        (asm "movl %ecx, 8(%esp)")
        (asm "movl $0, 4(%esp)")
        (asm "1:")
        (asm "movl 8(%esp), %ecx")
        (asm "test %ecx, %ecx")
        (asm "jz 2f")
        (vmsave)
        (call allocate_cons)
        (vmrestore)
        (asm "movl 4(%esp), %edx")
        (asm "movl %edx, 4(%eax)")
        (asm "movl (%esp), %edx")
        (asm "movl (%edx), %edx")
        (asm "movl %edx, (%eax)")
        (asm "movl %eax, 4(%esp)")
        (asm "subl $4, (%esp)")
        (asm "subl $1, 8(%esp)")
        (asm "jmp 1b")
        (asm "2:")
        (asm "movl 4(%esp), %eax")
        (asm "addl $12, %esp")
        (asm "xorl %edx, %edx")
        (vmpush %eax)
        ))
    (keys () @true ((asm "movl 16(%edi), %eax") (vmpush %eax)))
    (self () @true ((asm "movl 20(%edi), %eax") (vmpush %eax)))
    (arg0 () @true ((asm "movl 24(%edi), %eax") (vmpush %eax)))
    (arg1 () @true ((asm "movl 28(%edi), %eax") (vmpush %eax)))
    (arg2 () @true ((asm "movl 32(%edi), %eax") (vmpush %eax)))
    (arg3 () @true ((asm "movl 36(%edi), %eax") (vmpush %eax)))
    (arg4 () @true ((asm "movl 40(%edi), %eax") (vmpush %eax)))
    ; load word from local
    (loadl0 () @true ((asm "movl -4(%edi), %eax") (vmpush %eax)))
    (loadl1 () @true ((asm "movl -8(%edi), %eax") (vmpush %eax)))
    (loadl2 () @true ((asm "movl -12(%edi), %eax") (vmpush %eax)))
    (loadl3 () @true ((asm "movl -16(%edi), %eax") (vmpush %eax)))
    (loadl4 () @true ((asm "movl -20(%edi), %eax") (vmpush %eax)))
    (loadl5 () @true ((asm "movl -24(%edi), %eax") (vmpush %eax)))
    (loadl (byte) @true (
        (vmsbyte 1 %ecx) ; offset
        (asm "leal (%edi,%ecx,1), %eax")
        (asm "movl (%eax), %eax")
        (vmpush %eax)
        ))
    ; store word to local
    (storel0 () @true ((vmpop %eax) (asm "movl %eax, -4(%edi)")))
    (storel1 () @true ((vmpop %eax) (asm "movl %eax, -8(%edi)")))
    (storel2 () @true ((vmpop %eax) (asm "movl %eax, -12(%edi)")))
    (storel3 () @true ((vmpop %eax) (asm "movl %eax, -16(%edi)")))
    (storel4 () @true ((vmpop %eax) (asm "movl %eax, -20(%edi)")))
    (storel5 () @true ((vmpop %eax) (asm "movl %eax, -24(%edi)")))
    (storel (byte) @true (
        (vmsbyte 1 %ecx) ; index
        (asm "leal (%edi,%ecx,1), %eax")
        (vmpop %ecx)
        (asm "movl %ecx, (%eax)")
        ))
    (incrl0 () @true ((asm "addl $1, -4(%edi)")))
    (incrl1 () @true ((asm "addl $1, -8(%edi)")))
    (incrl2 () @true ((asm "addl $1, -12(%edi)")))
    (incrl3 () @true ((asm "addl $1, -16(%edi)")))
    (incrl4 () @true ((asm "addl $1, -20(%edi)")))
    (incrl5 () @true ((asm "addl $1, -24(%edi)")))
    (incrl (byte) @true (
        (vmsbyte 1 %ecx) ; index
        (asm "leal (%edi,%ecx,1), %eax")
        (asm "addl $1, (%eax)")
        ))
    (decrl0 () @true ((asm "subl $1, -4(%edi)")))
    (decrl1 () @true ((asm "subl $1, -8(%edi)")))
    (decrl2 () @true ((asm "subl $1, -12(%edi)")))
    (decrl3 () @true ((asm "subl $1, -16(%edi)")))
    (decrl4 () @true ((asm "subl $1, -20(%edi)")))
    (decrl5 () @true ((asm "subl $1, -24(%edi)")))
    (decrl (byte) @true (
        (vmsbyte 1 %ecx) ; index
        (asm "leal (%edi,%ecx,1), %eax")
        (asm "subl $1, (%eax)")
        ))
    (addrl (byte) @true (
        (vmsbyte 1 %ecx) ; index
        (asm "leal (%edi,%ecx,1), %eax")
        (vmpush %eax)
        ))
    ; load byte from value area
    (loadbv (ushort) @true (
        (vmushort 1 %eax)
        (asm "addl value_area_base, %eax")
        (asm "movsbl (%eax), %eax")
        (vmpush %eax)
        ))
    ; load word from value area
    (loadv (ushort) @true (
        (vmushort 1 %eax)
        (asm "addl value_area_base, %eax")
        (asm "movl (%eax), %eax")
        (vmpush %eax)
        ))
    ; load address of array from value area
    (loadav (ushort) @true (
        (vmushort 1 %eax)
        (asm "addl value_area_base, %eax")
        (vmpush %eax)
        ))
    ; store byte to value area
    (storebv (ushort) @true (
        (vmushort 1 %eax)
        (asm "addl value_area_base, %eax")
        (vmpop %ecx)
        (asm "movb %cl, (%eax)")
        ))
    ; store word to value area
    (storewv (ushort) @true (
        (vmushort 1 %eax)
        (asm "addl value_area_base, %eax")
        (vmpop %ecx)
        (asm "movl %ecx, (%eax)")
        ))
    ; load global heap object
    (loado (ushort) @true (
        (vmushort 1 %eax)
        (asm "shll $2, %eax")
        (asm "addl gobject_area_base, %eax")
        (asm "movl (%eax), %eax")
        (vmpush %eax)
        ))
    ; store global heap object
    (storeo (ushort) @true (
        (vmushort 1 %eax)
        (asm "shll $2, %eax")
        (asm "addl gobject_area_base, %eax")
        (vmpop %ecx)
        (asm "movl %ecx, (%eax)")
        ))
    ; 'fun:1' 'relative address of the function:2'
    (fun (addr) @true (
        (vmsshort 1 %eax) ; offset of address of the function
        (asm "addl %ebx, %eax") ; compute absloute address
        (asm "subl code_base, %eax")
        (vmpush %eax)
        ))
    ; 'lfun:1' 'relative address of the function:4'
    (lfun (laddr) @true (
        (vmint 1 %eax) ; offset of address of the function
        (asm "addl %ebx, %eax") ; compute absloute address
        (asm "subl code_base, %eax")
        (vmpush %eax)
        ))
    ; 'prim:1' 'index of the external function:2'
    (prim (prim) @true (
        (vmushort 1 %eax) ; index of the function
        (asm "orl  $0x80000000, %eax") ; set flag
        (vmpush %eax)
        ))
    (push (object) @true (
        (vmint 1 %eax)
        (vmpush %eax)
        ))
    ; 'call:1' 'relative address of the function:2' 'number of arguments:1'
    (call (addr byte) @nil  (
        (asm "subl $12, %esi")
        (asm "movl $" @C_UNDEF ", 8(%esi)")
        (vmubyte 3 %eax)
        (asm "shll $2, %eax")
        (vmpush %eax) ; store size of arguments
        (asm "movl %ebx, %eax")
        (asm "addl $4, %eax")
        (vmpush %eax) ; store return point

        (asm "movl %edi, %eax") ; old base pointer
        (asm "subl %esi, %eax")
        (vmpush %eax) ; store frame size

        (asm "movl %esi, %edi") ; set new base pointer
        (vmsshort 1 %eax) ; offset of address of the function
        (asm "addl %eax, %ebx")
        (vmfetch)
        ))
    ; 'lcall:1' 'relative address of the function:4' 'number of arguments:1'
    (lcall (laddr byte) @nil (
        (asm "subl $12, %esi") ; stp -> |closure|kwarg|self|
        (asm "movl $" @C_UNDEF ", 8(%esi)")
        (asm "movl $0, 4(%esi)")
        (asm "movl $0, (%esi)")

        (vmubyte 5 %eax)
        (asm "shll $2, %eax")
        (vmpush %eax) ; store size of arguments
        (asm "movl %ebx, %eax")
        (asm "addl $6, %eax")
        (vmpush %eax) ; store return point
        (asm "movl %edi, %eax") ; old base pointer
        (asm "subl %esi, %eax")
        (vmpush %eax) ; store frame size
        (asm "movl %esi, %edi") ; set base pointer
        (vmint 1 %eax) ; offset of address of the function
        (asm "addl %eax, %ebx")
        (vmfetch)
        ))
    ; 'pcall:1' 'index of the external function:2' 'number of arguments:1'
    (pcall (prim byte) @true (
        (vmsave)
        (vmushort 1 %eax)
        (vmubyte 3 %ecx)
        (asm "shll $2, %ecx")
        (asm "pushl %esi") ; push argv
        (asm "pushl %ecx") ; push argsize
        (asm "pushl %eax") ; push index
        (call vm_pcall)
        (asm "addl $12, %esp")
        (vmrestore)
        (vmubyte 3 %ecx) ; number of arguments
        (asm "shll $2, %ecx")
        (asm "addl %ecx, %esi") ; remove arguments from stack
        (vmpush %eax) ; push return value
        ))
    ; 'acall:1' 'number of arguments:1'
    (acall (byte) @nil (
        (asm "movl %ebx, %ecx")
        (asm "addl $2, %ecx")
        (vmubyte 1 %eax)
        (asm "shll $2, %eax")
        (vmpop %ebx)
        (asm "subl $12, %esi") ; stp -> |closure|kwarg|self|
        (asm "movl $" @C_UNDEF ", 8(%esi)")
        (asm "movl $0, 4(%esi)")
        (asm "movl $0, (%esi)")

        (vmpush %eax) ; store size of arguments
        (vmpush %ecx) ; store return point
        (asm "movl %edi, %eax") ; old base pointer
        (asm "subl %esi, %eax")
        (vmpush %eax) ; store frame size
        (asm "movl %esi, %edi") ; set base pointer
        (asm "addl code_base, %ebx")
        (vmfetch)
        ))
    ; 'aforward:1'
    (aforward () @nil (
        (vmpop %ebx)
        (asm "addl code_base, %ebx")
        (vmfetch)
        ))
    ; 'jcall:1' 'number of arguments:1' 'self-flag:1'
    (jcall (byte byte) @nil (
        (asm "movl %ebx, %ecx")
        (asm "addl $3, %ecx")
        (vmubyte 1 %eax)
        (asm "shll $2, %eax")
        (asm "pushl %eax")
        (vmubyte 2 %edx)
        (vmpop %ebx)

        (asm "testl $1, %edx")
        (asm "jz 1f")
        (asm "testl $2, %edx")
        (asm "jz 2f")
        ; call with self and keyword arg
        (asm "subl $4, %esi")
        (asm "movl $0, (%esi)")
        (asm "jmp 5f")
        (asm "2:")
        ; call with self
        (asm "subl $8, %esi")
        (asm "movl $0, (%esi)")
        (asm "movl $0, 4(%esi)")
        (asm "jmp 5f")
        (asm "1:")
        (asm "testl $2, %edx")
        (asm "jz 4f")
        ; call with keyword arg
        (asm "subl $8, %esi")
        (asm "movl 8(%esi), %eax")
        (asm "movl %eax, 4(%esi)")
        (asm "movl $0, (%esi)")
        (asm "movl 20(%edi), %eax")
        (asm "movl %eax, 8(%esi)")
        (asm "jmp 5f")
        (asm "4:")
        ; call with no keyword arg and self
        (asm "subl $12, %esi")
        (asm "movl $0, (%esi)")
        (asm "movl $0, 4(%esi)")
        (asm "movl 20(%edi), %eax")
        (asm "movl %eax, 8(%esi)")
        (asm "5:")
        (asm "xorl %edx, %edx")

        (asm "popl %eax")
        (asm "addl $12, %ebx") ; pointer to the bytecode
        (vmpush %eax) ; store size of arguments
        (vmpush %ecx) ; store return point
        (asm "movl %edi, %eax") ; old base pointer
        (asm "subl %esi, %eax")
        (vmpush %eax) ; store frame size
        (asm "movl %esi, %edi") ; set base pointer
        (vmfetch)
        ))
    (jjump () @nil (
        (vmpop %ebx)
        (asm "addl $12, %ebx") ; pointer to the bytecode
        (vmfetch)
        ))
    (return () @nil  (
        (asm "movl %edi, %esi")
        (vmpop %eax) ; frame size
        (asm "movl %esi, %edi")
        (asm "addl %eax, %edi")
        (vmpop %ebx) ; return address
        (vmpop %eax) ; total size of arguments
        (asm "movzbl %al, %ecx")

        (asm "addl $12, %esi") ; closure,kwarg,self
        (asm "addl %ecx, %esi")
        (vmpush 0) ; push return value

        (asm "andl $" @RESET_MARK ", %eax")
        (asm "jnz 1f")
        (vmfetch)
        (asm "1:")
        (asm "movl resetstack, %ecx")
        (asm "movl 12(%ecx), %ecx")
        (asm "movl %ecx, resetstack")
        (vmfetch)
        ))
    (ireturn () @nil  (
        (asm "movl (%esi), %ecx") ; return value
        (asm "movl %edi, %esi")
        (vmpop %eax) ; frame size
        (asm "movl %esi, %edi")
        (asm "addl %eax, %edi")
        (vmpop %ebx) ; return address
        (vmpop %eax) ; total size of arguments
        (asm "movzbl %al, %edx")
        (asm "addl $12, %esi") ; closure,kwarg,self
        (asm "addl %edx, %esi")
        (asm "xorl %edx, %edx")
        (vmpush %ecx) ; push return value

        (asm "andl $" @RESET_MARK ", %eax")
        (asm "jnz 1f")
        (vmfetch)
        (asm "1:")
        (asm "movl resetstack, %ecx")
        (asm "movl 12(%ecx), %ecx")
        (asm "movl %ecx, resetstack")
        (vmfetch)
        ))
    (expand () @true (
        (vmpop %eax)
        (asm "xorl %ecx, %ecx")
        (asm "1:")
        (asm "testl %eax, %eax")
        (asm "jz 2f")
        (asm "movl (%eax), %edx")
        (asm "movl 4(%eax), %eax")
        (asm "addl $1, %ecx")
        (asm "subl $4, %esi")
        (asm "movl %edx, (%esi)")
        (asm "jmp 1b")
        (asm "2:")
        (asm "xorl %edx, %edx")
        (vmpush %ecx)
        ))
    ; 'vcall:1' 'self-flag:1'
    (vcall (byte) @nil (
        (asm "movl %ebx, %ecx")
        (asm "addl $2, %ecx")
        (vmpop %eax)
        (asm "shll $2, %eax") ; number of arguments
        (vmubyte 1 %edx)
        (vmpop %ebx)
        (asm "pushl %eax")

        (asm "testl $1, %edx")
        (asm "jz 1f")
        (asm "testl $2, %edx")
        (asm "jz 2f")
        ; call with self and keyword arg
        (asm "subl $4, %esi")
        (asm "movl $0, (%esi)")
        (asm "jmp 5f")
        (asm "2:")
        ; call with self
        (asm "subl $8, %esi")
        (asm "movl $0, (%esi)")
        (asm "movl $0, 4(%esi)")
        (asm "jmp 5f")
        (asm "1:")
        (asm "testl $2, %edx")
        (asm "jz 4f")
        ; call with keyword arg
        (asm "subl $8, %esi")
        (asm "movl 8(%esi), %eax")
        (asm "movl %eax, 4(%esi)")
        (asm "movl $0, (%esi)")
        (asm "movl 20(%edi), %eax")
        (asm "movl %eax, 8(%esi)")
        (asm "jmp 5f")
        (asm "4:")
        ; call with no keyword arg and self
        (asm "subl $12, %esi")
        (asm "movl $0, (%esi)")
        (asm "movl $0, 4(%esi)")
        (asm "movl 20(%edi), %eax")
        (asm "movl %eax, 8(%esi)")
        (asm "5:")
        (asm "xorl %edx, %edx")


        (asm "popl %eax")
        (asm "addl $12, %ebx") ; pointer to the bytecode
        (vmpush %eax) ; store size of arguments
        (vmpush %ecx) ; store return point
        (asm "movl %edi, %eax") ; old base pointer
        (asm "subl %esi, %eax")
        (vmpush %eax) ; store frame size
        (asm "movl %esi, %edi") ; set base pointer
        (vmfetch)
        ))
    ; switch (table search)
    (tswitch (ushort) @nil (
        (vmpop %eax)
        (vmushort 1 %ecx) ; number of cases
        (asm "cmpl %eax, %ecx")
        (asm "cmovle %ecx, %eax")
        (asm "cmpl $0, %eax")
        (asm "cmovl %ecx, %eax")
        (asm "cmpl %eax, %edx")
        (asm "cmova %ecx, %eax")
        (asm "sall $1, %eax")
        (asm "addl $3, %ebx")
        (asm "addl %eax, %ebx")
        (asm "movzwl (%ebx), %eax")
        (asm "addl %eax, %ebx")
        (vmfetch)
        ))
    ; switch (linear search)
    (lswitch (int) @nil (
        (vmpop %eax)
        (vmint 1 %ecx) ; maximum value of case values
        (asm "addl $5, %ebx")
        (asm "1:")
        (asm "movl (%ebx), %edx") ; case value
        (asm "cmpl %eax, %edx")
        (asm "je 2f")
        (asm "cmpl %ecx, %edx")
        (asm "je 2f")
        (asm "addl $6, %ebx")
        (asm "jmp 1b")
        (asm "2:")
        (asm "xorl %edx, %edx") ; zero clear
        (asm "movzwl 4(%ebx), %eax")
        (asm "addl %eax, %ebx")
        (vmfetch)
        ))
    (goto       (addr) @nil ((vmsshort 1 %eax) (asm "addl %eax, %ebx") (vmfetch)))
    (if_zero    (addr) @nil @(gen_comparison1 "cmovz"))
    (if_nonzero (addr) @nil @(gen_comparison1 "cmovnz"))
    (if_eq      (addr) @nil @(gen_comparison2 "cmove"))
    (if_ne      (addr) @nil @(gen_comparison2 "cmovne"))
    (if_gt      (addr) @nil @(gen_comparison2 "cmovg"))
    (if_ge      (addr) @nil @(gen_comparison2 "cmovge"))
    (if_lt      (addr) @nil @(gen_comparison2 "cmovl"))
    (if_le      (addr) @nil @(gen_comparison2 "cmovle"))
    (if_ugt     (addr) @nil @(gen_comparison2 "cmova"))
    (if_uge     (addr) @nil @(gen_comparison2 "cmovae"))
    (if_ult     (addr) @nil @(gen_comparison2 "cmovb"))
    (if_ule     (addr) @nil @(gen_comparison2 "cmovbe"))

    (if_feq     (addr) @nil @(gen_comparison3 "je"))
    (if_fne     (addr) @nil @(gen_comparison3 "jne"))
    (if_fgt     (addr) @nil @(gen_comparison3 "ja"))
    (if_fge     (addr) @nil @(gen_comparison3 "jae"))
    (if_flt     (addr) @nil @(gen_comparison3 "jb"))
    (if_fle     (addr) @nil @(gen_comparison3 "jbe"))

    (if_nil    (addr) @nil @(gen_comparison4 C_NIL))
    (if_undef  (addr) @nil @(gen_comparison4 C_UNDEF))
    (if_true   (addr) @nil (
        (vmpop %eax)
        (asm "cmpl $" @C_FALSE ", %eax")
        (asm "je 1f")
        (asm "cmpl $" @C_NIL ", %eax")
        (asm "je 1f")
        (vmsshort 1 %ecx)
        (vmsucc %ecx)
        (vmfetch)
        (asm "1:")
        (vmsucc 3)
        (vmfetch)
        ))
    (if_false  (addr) @nil (
        (vmpop %eax)
        (asm "cmpl $" @C_FALSE ", %eax")
        (asm "je 1f")
        (asm "cmpl $" @C_NIL ", %eax")
        (asm "je 1f")
        (vmsucc 3)
        (vmfetch)
        (asm "1:")
        (vmsshort 1 %ecx)
        (vmsucc %ecx)
        (vmfetch)
        ))
    
    ; 'rcall:1'
    (rcall () @nil (
        (vmsave)
        (asm "pushl $16")
        (asm "pushl $" @PLAIN_OTHER)
        (call allocate_pstruct)
        (asm "addl $8, %esp")
        (vmrestore)
        (asm "movl %esi, %ecx")
        (asm "addl $4, %ecx")   ; remove unnecessary frame
        (asm "movl %ecx, (%eax)")
        (asm "movl %edi, 4(%eax)")
        (asm "movl resetstack, %ecx")
        (asm "movl %ecx, 12(%eax)")
        (asm "movl %ebx, %ecx")
        (asm "addl $1, %ecx")
        (asm "movl %ecx, 8(%eax)")
        (asm "movl %eax, resetstack")

        (vmpop %ebx)
        (asm "subl $12, %esi") ; stp -> |closure|kwarg|self|
        (asm "movl 20(%edi), %eax")
        (asm "movl %eax, 8(%esi)")
        (asm "movl $0, 4(%esi)")
        (asm "movl $0, (%esi)")

        (asm "addl $12, %ebx") ; pointer to the bytecode
        (vmpush @RESET_MARK) ; store size of arguments (== 0) and 'reset' mark
        (vmpush %ecx) ; store return point
        (asm "movl %edi, %eax") ; old base pointer
        (asm "subl %esi, %eax")
        (vmpush %eax) ; store frame size
        (asm "movl %esi, %edi") ; set base pointer
        (vmfetch)
        ))

    (shift () @nil (
        (vmsave)
        (asm "movl resetstack, %edx")
        (asm "pushl (%edx)")    ; stack top at `reset'
        (asm "movl %esi, %eax")
        (asm "addl $4, %eax")
        (asm "pushl %eax")      ; stack top at `shift'
        (asm "movl %ebx, %eax")
        (asm "addl $1, %eax")
        (asm "pushl %edi")      ; base pointer
        (asm "pushl %eax")      ; program counter
        (call prim_make_continuation)
        (asm "addl $16, %esp")
        (vmrestore)
        (vmpop %ebx)
        (asm "addl $12, %ebx") ; pointer to the bytecode

        (asm "movl resetstack, %edx")
        (asm "movl 8(%edx), %ecx")
        (asm "movl 4(%edx), %edi")
        (asm "movl (%edx), %esi")
        (asm "movl 12(%edx), %edx")
        (asm "movl %edx, resetstack")
        (asm "xorl %edx, %edx")

        (vmpush %eax)
        (asm "subl $12, %esi") ; stp -> |closure|kwarg|self|
        (asm "movl 20(%edi), %eax")
        (asm "movl %eax, 8(%esi)")
        (asm "movl $0, 4(%esi)")
        (asm "movl $0, (%esi)")

        (vmpush 4)    ; store size of arguments
        (vmpush %ecx) ; store return point
        (asm "movl %edi, %eax") ; old base pointer
        (asm "subl %esi, %eax")
        (vmpush %eax) ; store frame size
        (asm "movl %esi, %edi") ; set base pointer
        (vmfetch)
        ))

    (callc () @nil (
        ; push reset mark
        (vmsave)
        (asm "pushl $16")
        (asm "pushl $" @PLAIN_OTHER)
        (call allocate_pstruct)
        (asm "addl $8, %esp")
        (vmrestore)
        (asm "movl %esi, %ecx")
        (asm "addl $28, %ecx")   ; remove unnecessary frame
        (asm "movl %ecx, (%eax)")

        (asm "movl (%edi), %ecx") ; frame size
        (asm "addl $4, %ecx")
        (asm "addl %edi, %ecx")   ; base pointer of caller
        (asm "movl %ecx, 4(%eax)")

        (asm "movl 4(%edi), %ecx")
        (asm "movl %ecx, 8(%eax)") ; return point

        (asm "movl resetstack, %ecx")
        (asm "movl %ecx, 12(%eax)")
        (asm "movl %eax, resetstack")

        (asm "movl 24(%edi), %eax")
        (asm "pushl %eax")  ; arg0
        (asm "orl $" @RESET_MARK ", 8(%edi)")
        (vmpop %eax)    ; continuation
        (asm "movl (%eax), %ebx")
        (asm "movl 8(%eax), %edi")
        (asm "movl 16(%eax), %ecx") ; size of evacuated stack
        (asm "movl 12(%eax), %eax") ; stack bottom
        (asm "addl %ecx, %eax")

        (asm "1:")
        (asm "testl %ecx, %ecx")
        (asm "jz 2f")
        (asm "subl $4, %esi")
        (asm "subl $4, %eax")
        (asm "movl (%eax), %edx")
        (asm "movl %edx, (%esi)")
        (asm "subl $1, %ecx")
        (asm "jmp 1b")

        (asm "2:")
        (asm "xorl %edx, %edx")
        (asm "addl %esi, %edi")
        (asm "popl %eax")
        (vmpush %eax) ; arg0
        (vmfetch)
        ))

    ; instructions for handling exceptions.
    ; push unwind stack
    (unwind_push (addr) @true (
        (vmsave)
        (asm "pushl $16")
        (asm "pushl $" @PLAIN_OTHER)
        (call allocate_pstruct)
        (asm "addl $8, %esp")
        (vmrestore)
        (vmsshort 1 %ecx)
        (asm "addl %ebx, %ecx") ; address of handler
        (asm "movl %ecx, (%eax)")
        (asm "movl %esi, 4(%eax)")
        (asm "movl %edi, 8(%eax)")
        (asm "movl exstack, %ecx")
        (asm "movl %ecx, 12(%eax)")
        (asm "movl %eax, exstack")
        ))
    ; pop unwind stack
    (unwind_pop () @true (
        (asm "movl exstack, %eax")
        (asm "movl 12(%eax), %eax")
        (asm "movl %eax, exstack")
        ))
    ; throw given value
    (throw () @nil (
        (vmpop %ecx)    ; exception value
        (asm "movl exstack, %eax")
        (asm "movl (%eax), %ebx")
        (asm "movl 4(%eax), %esi")
        (asm "movl 8(%eax), %edi")
        (asm "movl 12(%eax), %eax")
        (asm "movl %eax, exstack")
        (vmpush %ecx)
        (vmfetch)
        ))

    (exit () @nil ((vmpop %eax) (break)))

    (check_int  (addr) @nil (
        (vmpop %eax)
        (vmsshort 1 %ecx)
        (asm "andl $1, %eax")
        (asm "movl $3, %eax")
        (asm "cmovz %ecx, %eax")
        (vmsucc %eax)
        (vmfetch)
        ))
    (check_string (addr) @nil @(gen_check_pstruct PLAIN_STRING))
    (check_list (addr int) @nil (
        ; XXX: should not hardcode the layout of object header.
        (vmpop %eax)
        (vmint 3 %ecx)
        (asm "0:")
        (asm "testl %eax, %eax")
        (asm "jz 1f")
        (asm "cmpl $" @SPECIAL_MAX ", %eax")
        (asm "jbe 3f") ; if %eax <= SPECIAL_MAX then %eax is a unboxed data.
        (asm "testl $1, %eax")
        (asm "jnz 3f")
        (asm "movl -4(%eax), %edx") ; %edx <- header of %eax
        (asm "andl $15, %edx")
        (asm "cmpl $" @TAG_CONS ", %edx")
        (asm "jne 3f")
        (asm "movl 4(%eax), %eax") ; %eax <- cdr %eax
        (asm "subl $1, %ecx")
        (asm "jmp 0b")
        (asm "1:")
        (asm "testl %ecx, %ecx")
        (asm "jz 2f")
        (asm "3:") ; here, %eax is not a list of length %ecx.
        (asm "xorl %edx, %edx")
        (vmsshort 1 %ecx)
        (vmsucc %ecx)
        (vmfetch)
        (asm "2:")
        (asm "xorl %edx, %edx")
        (vmsucc 7)
        (vmfetch)
        ))
    (check_list2 (addr int) @nil (
        ; XXX: should not hardcode the layout of object header.
        (vmpop %eax)
        (vmint 3 %ecx)
        (asm "0:")
        (asm "testl %eax, %eax")
        (asm "jz 1f")
        (asm "testl %ecx, %ecx")
        (asm "jz 2f")
        (asm "cmpl $" @SPECIAL_MAX ", %eax")
        (asm "jbe 3f") ; if %eax <= SPECIAL_MAX then %eax is a unboxed data.
        (asm "testl $1, %eax")
        (asm "jnz 3f")
        (asm "movl -4(%eax), %edx") ; %edx <- header of %eax
        (asm "andl $15, %edx")
        (asm "cmpl $" @TAG_CONS ", %edx")
        (asm "jne 3f")
        (asm "movl 4(%eax), %eax") ; %eax <- cdr %eax
        (asm "subl $1, %ecx")
        (asm "jmp 0b")
        (asm "1:")
        (asm "testl %ecx, %ecx")
        (asm "jnz 3f")
        (asm "2:")
        (asm "xorl %edx, %edx")
        (vmsucc 7)
        (vmfetch)
        (asm "3:")
        (asm "xorl %edx, %edx")
        (vmsshort 1 %ecx)
        (vmsucc %ecx)
        (vmfetch)
        ))
    ))

; insn-name -> (code len)
(var vm_insn_table (do
    (var code 0)
    (var entries ())
    (foreach i vm_instructions (do
        (var name (car i))
        (var len  (insn_length (cadr i)))
        (push entries `(@name @code @len))
        (incr code)
        ))
    (reverse entries)
    ))

(define IS_PRIM (v) `(< @v 0))
(define PRIM_IDX (v) `(& @v 0xffff))
